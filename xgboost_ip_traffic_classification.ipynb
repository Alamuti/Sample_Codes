{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------\n",
    "# Trains a XGBoost model to predict pirating ips from the daily ip level traffic data.\n",
    "#\n",
    "# Author: Mohsen Mohammadi - Nov 2020\n",
    "# Version: 1\n",
    "# \n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "size = 25\n",
    "params = {'legend.fontsize': size,\n",
    "          'figure.figsize': (25,15),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75,\n",
    "          'axes.titlepad': 25}\n",
    "plt.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:07:59] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 83.0% \n"
     ]
    }
   ],
   "source": [
    "# linear regression feature importance\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define dataset\n",
    "ip_train = pd.read_csv('/home/jupyter/preprocessing/data/3C/IP_TRAIN_d.csv')\n",
    "ip_test = pd.read_csv('/home/jupyter/preprocessing/data/3C/IP_TEST_d.csv')\n",
    "\n",
    "ip_train = ip_train.iloc[:,:-30]\n",
    "ip_test = ip_test.iloc[:,:-30]\n",
    "\n",
    "ip_train.columns = range(ip_train.shape[1])\n",
    "ip_test.columns = range(ip_test.shape[1])\n",
    "train_x, train_y = ip_train, ip_train.pop(0)\n",
    "test_x, test_y = ip_test, ip_test.pop(0)\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dtest = xgb.DMatrix(test_x, label=test_y)\n",
    "\n",
    "# define the model parameters\n",
    "# Best: 0.889797 using {'subsample': 0.8999999999999999, 'min_child_weight': 0.6, 'max_depth': 9,\n",
    "#                       'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.5}\n",
    "param = {\n",
    "    'max_depth': 9,  \n",
    "    'eta': 0.1,  \n",
    "    'silent': 0,  \n",
    "    'num_class': 3,\n",
    "    'min_child_weight': 0.6,\n",
    "    'gamma': 0.1,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'objective': 'multi:softprob'\n",
    "    }  \n",
    "num_round = 500  # the number of training iterations\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "# evaluate the model\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "print(\"Accuracy: %0.1f%% \" % (accuracy * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.savefig('XGBClassifier.png')\n",
    "pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'detected_IPs_traffic_gw14_non_streaming_ips.csv'\n",
    "model_path = 'tf-keras/logs/cnn_export/20201223-124940'\n",
    "\n",
    "# Load and pre-process the IP level traffic data\n",
    "ip_traffic = pd.read_csv(filename, usecols=['time', 'ip', 'gbps'])\n",
    "ip_traffic['time'] = pd.to_datetime(ip_traffic['time'])\n",
    "ip_traffic['date'] = ip_traffic['time'].apply(lambda d: d.date())\n",
    "ip_traffic['time'] = ip_traffic['time'].apply(lambda d: d.time())\n",
    "\n",
    "ip_traffic = pd.pivot_table(ip_traffic, values='gbps', index=['date', 'ip'], columns='time', aggfunc=np.sum).fillna(0)\n",
    "ip_traffic = ip_traffic.iloc[:,:-30]\n",
    "\n",
    "ip_traffic['pred_label'] = y_pred[:, 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define dataset\n",
    "ip_test = pd.read_csv('/home/jupyter/preprocessing/data/ML/IP_TEST_stream.csv')\n",
    "test_x = ip_traffic.reset_index(drop=True)\n",
    "test_x.columns = range(1, ip_test.shape[1]+1)\n",
    "\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "print(\"Accuracy: %0.1f%% \" % (accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "#### Create X and Y training data here.....\n",
    "\n",
    "\n",
    "# grid search\n",
    "model = XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "        'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "        'min_child_weight': np.arange(0.1, 2, 0.1),\n",
    "        'gamma': [0, 0.0005, 0.001, 0.01, 0.1, 1, 10],\n",
    "        'learning_rate': [0.0005, 0.001, 0.01, 0.1],\n",
    "        'subsample': np.arange(0.5,1.0,0.1),\n",
    "        'colsample_bytree': np.arange(0.5,1.0,0.1)\n",
    "        }\n",
    "                                      \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=10)\n",
    "grid_search = RandomizedSearchCV(model, param_grid, scoring=\"accuracy\", n_iter = 500, cv=kfold)\n",
    "grid_result = grid_search.fit(train_x, train_y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[ 'mean_test_score' ]\n",
    "stds = grid_result.cv_results_[ 'std_test_score' ]\n",
    "params = grid_result.cv_results_[ 'params' ]\n",
    "\n",
    "print(time.time()-start_time)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
